{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anconda的安装\n",
    "- [Anconda下载地址](https://www.anaconda.com/distribution/#download-section)\n",
    "- [安装教程](https://www.cnblogs.com/amanda-x/p/7739467.html)\n",
    "<br>*建议*：选择Python 3.7 version\n",
    "<br>**注意事项**：注意电脑是windows还是mac系统"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 基础(自行阅读部分）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一个Python语句"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 + 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello, world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 基础\n",
    "阅读下面的文档\n",
    "- [数据类型和变量](https://www.liaoxuefeng.com/wiki/1016959663602400/1017063826246112)\n",
    "- [字符串和编码](https://www.liaoxuefeng.com/wiki/1016959663602400/1017075323632896)\n",
    "- [使用list和tuple](https://www.liaoxuefeng.com/wiki/1016959663602400/1017092876846880)\n",
    "- [条件和判断](https://www.liaoxuefeng.com/wiki/1016959663602400/1017099478626848)\n",
    "- [循环](https://www.liaoxuefeng.com/wiki/1016959663602400/1017100774566304)\n",
    "- [使用dict和set](https://www.liaoxuefeng.com/wiki/1016959663602400/1017104324028448)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juypter Notebook的使用\n",
    "- Juypter Notebook 的启动（指定文件夹下的启动）\n",
    "- 运行、Markdown与code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package 的安装和调用\n",
    "- empyrical包的安装\n",
    "<br>cmd 中 ```pip install empyrical```\n",
    "<br>juypter notebook 中```import empyrical```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据导入\n",
    "- 案例数据：XX_CTA策略-20190404.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('XX1号产品净值-20190404.xlsx', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_excel in module pandas.io.excel:\n",
      "\n",
      "read_excel(io, sheet_name=0, header=0, names=None, index_col=None, parse_cols=None, usecols=None, squeeze=False, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skiprows=None, nrows=None, na_values=None, keep_default_na=True, verbose=False, parse_dates=False, date_parser=None, thousands=None, comment=None, skip_footer=0, skipfooter=0, convert_float=True, mangle_dupe_cols=True, **kwds)\n",
      "    Read an Excel file into a pandas DataFrame.\n",
      "    \n",
      "    Support both `xls` and `xlsx` file extensions from a local filesystem or URL.\n",
      "    Support an option to read a single sheet or a list of sheets.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    io : str, file descriptor, pathlib.Path, ExcelFile or xlrd.Book\n",
      "        The string could be a URL. Valid URL schemes include http, ftp, s3,\n",
      "        gcs, and file. For file URLs, a host is expected. For instance, a local\n",
      "        file could be /path/to/workbook.xlsx.\n",
      "    sheet_name : str, int, list, or None, default 0\n",
      "        Strings are used for sheet names. Integers are used in zero-indexed\n",
      "        sheet positions. Lists of strings/integers are used to request\n",
      "        multiple sheets. Specify None to get all sheets.\n",
      "    \n",
      "        Available cases:\n",
      "    \n",
      "        * Defaults to ``0``: 1st sheet as a `DataFrame`\n",
      "        * ``1``: 2nd sheet as a `DataFrame`\n",
      "        * ``\"Sheet1\"``: Load sheet with name \"Sheet1\"\n",
      "        * ``[0, 1, \"Sheet5\"]``: Load first, second and sheet named \"Sheet5\"\n",
      "          as a dict of `DataFrame`\n",
      "        * None: All sheets.\n",
      "    \n",
      "    header : int, list of int, default 0\n",
      "        Row (0-indexed) to use for the column labels of the parsed\n",
      "        DataFrame. If a list of integers is passed those row positions will\n",
      "        be combined into a ``MultiIndex``. Use None if there is no header.\n",
      "    names : array-like, default None\n",
      "        List of column names to use. If file contains no header row,\n",
      "        then you should explicitly pass header=None.\n",
      "    index_col : int, list of int, default None\n",
      "        Column (0-indexed) to use as the row labels of the DataFrame.\n",
      "        Pass None if there is no such column.  If a list is passed,\n",
      "        those columns will be combined into a ``MultiIndex``.  If a\n",
      "        subset of data is selected with ``usecols``, index_col\n",
      "        is based on the subset.\n",
      "    parse_cols : int or list, default None\n",
      "        Alias of `usecols`.\n",
      "    \n",
      "        .. deprecated:: 0.21.0\n",
      "           Use `usecols` instead.\n",
      "    \n",
      "    usecols : int, str, list-like, or callable default None\n",
      "        Return a subset of the columns.\n",
      "        * If None, then parse all columns.\n",
      "        * If int, then indicates last column to be parsed.\n",
      "    \n",
      "        .. deprecated:: 0.24.0\n",
      "           Pass in a list of int instead from 0 to `usecols` inclusive.\n",
      "    \n",
      "        * If str, then indicates comma separated list of Excel column letters\n",
      "          and column ranges (e.g. \"A:E\" or \"A,C,E:F\"). Ranges are inclusive of\n",
      "          both sides.\n",
      "        * If list of int, then indicates list of column numbers to be parsed.\n",
      "        * If list of string, then indicates list of column names to be parsed.\n",
      "    \n",
      "        .. versionadded:: 0.24.0\n",
      "    \n",
      "        * If callable, then evaluate each column name against it and parse the\n",
      "          column if the callable returns ``True``.\n",
      "    \n",
      "        .. versionadded:: 0.24.0\n",
      "    \n",
      "    squeeze : bool, default False\n",
      "        If the parsed data only contains one column then return a Series.\n",
      "    dtype : Type name or dict of column -> type, default None\n",
      "        Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32}\n",
      "        Use `object` to preserve data as stored in Excel and not interpret dtype.\n",
      "        If converters are specified, they will be applied INSTEAD\n",
      "        of dtype conversion.\n",
      "    \n",
      "        .. versionadded:: 0.20.0\n",
      "    \n",
      "    engine : str, default None\n",
      "        If io is not a buffer or path, this must be set to identify io.\n",
      "        Acceptable values are None or xlrd.\n",
      "    converters : dict, default None\n",
      "        Dict of functions for converting values in certain columns. Keys can\n",
      "        either be integers or column labels, values are functions that take one\n",
      "        input argument, the Excel cell content, and return the transformed\n",
      "        content.\n",
      "    true_values : list, default None\n",
      "        Values to consider as True.\n",
      "    \n",
      "        .. versionadded:: 0.19.0\n",
      "    \n",
      "    false_values : list, default None\n",
      "        Values to consider as False.\n",
      "    \n",
      "        .. versionadded:: 0.19.0\n",
      "    \n",
      "    skiprows : list-like\n",
      "        Rows to skip at the beginning (0-indexed).\n",
      "    nrows : int, default None\n",
      "        Number of rows to parse.\n",
      "    \n",
      "        .. versionadded:: 0.23.0\n",
      "    \n",
      "    na_values : scalar, str, list-like, or dict, default None\n",
      "        Additional strings to recognize as NA/NaN. If dict passed, specific\n",
      "        per-column NA values. By default the following values are interpreted\n",
      "        as NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
      "        '1.#IND', '1.#QNAN', 'N/A', 'NA', 'NULL', 'NaN', 'n/a', 'nan',\n",
      "        'null'.\n",
      "    keep_default_na : bool, default True\n",
      "        If na_values are specified and keep_default_na is False the default NaN\n",
      "        values are overridden, otherwise they're appended to.\n",
      "    verbose : bool, default False\n",
      "        Indicate number of NA values placed in non-numeric columns.\n",
      "    parse_dates : bool, list-like, or dict, default False\n",
      "        The behavior is as follows:\n",
      "    \n",
      "        * bool. If True -> try parsing the index.\n",
      "        * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
      "          each as a separate date column.\n",
      "        * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
      "          a single date column.\n",
      "        * dict, e.g. {{'foo' : [1, 3]}} -> parse columns 1, 3 as date and call\n",
      "          result 'foo'\n",
      "    \n",
      "        If a column or index contains an unparseable date, the entire column or\n",
      "        index will be returned unaltered as an object data type. For non-standard\n",
      "        datetime parsing, use ``pd.to_datetime`` after ``pd.read_csv``\n",
      "    \n",
      "        Note: A fast-path exists for iso8601-formatted dates.\n",
      "    date_parser : function, optional\n",
      "        Function to use for converting a sequence of string columns to an array of\n",
      "        datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
      "        conversion. Pandas will try to call `date_parser` in three different ways,\n",
      "        advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
      "        (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
      "        string values from the columns defined by `parse_dates` into a single array\n",
      "        and pass that; and 3) call `date_parser` once for each row using one or\n",
      "        more strings (corresponding to the columns defined by `parse_dates`) as\n",
      "        arguments.\n",
      "    thousands : str, default None\n",
      "        Thousands separator for parsing string columns to numeric.  Note that\n",
      "        this parameter is only necessary for columns stored as TEXT in Excel,\n",
      "        any numeric columns will automatically be parsed, regardless of display\n",
      "        format.\n",
      "    comment : str, default None\n",
      "        Comments out remainder of line. Pass a character or characters to this\n",
      "        argument to indicate comments in the input file. Any data between the\n",
      "        comment string and the end of the current line is ignored.\n",
      "    skip_footer : int, default 0\n",
      "        Alias of `skipfooter`.\n",
      "    \n",
      "        .. deprecated:: 0.23.0\n",
      "           Use `skipfooter` instead.\n",
      "    skipfooter : int, default 0\n",
      "        Rows at the end to skip (0-indexed).\n",
      "    convert_float : bool, default True\n",
      "        Convert integral floats to int (i.e., 1.0 --> 1). If False, all numeric\n",
      "        data will be read in as floats: Excel stores all numbers as floats\n",
      "        internally.\n",
      "    mangle_dupe_cols : bool, default True\n",
      "        Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
      "        'X'...'X'. Passing in False will cause data to be overwritten if there\n",
      "        are duplicate names in the columns.\n",
      "    **kwds : optional\n",
      "            Optional keyword arguments can be passed to ``TextFileReader``.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame or dict of DataFrames\n",
      "        DataFrame from the passed in Excel file. See notes in sheet_name\n",
      "        argument for more information on when a dict of DataFrames is returned.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    to_excel : Write DataFrame to an Excel file.\n",
      "    to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      "    read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
      "    read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    The file can be read using the file name as string or an open file object:\n",
      "    \n",
      "    >>> pd.read_excel('tmp.xlsx', index_col=0)  # doctest: +SKIP\n",
      "           Name  Value\n",
      "    0   string1      1\n",
      "    1   string2      2\n",
      "    2  #Comment      3\n",
      "    \n",
      "    >>> pd.read_excel(open('tmp.xlsx', 'rb'),\n",
      "    ...               sheet_name='Sheet3')  # doctest: +SKIP\n",
      "       Unnamed: 0      Name  Value\n",
      "    0           0   string1      1\n",
      "    1           1   string2      2\n",
      "    2           2  #Comment      3\n",
      "    \n",
      "    Index and header can be specified via the `index_col` and `header` arguments\n",
      "    \n",
      "    >>> pd.read_excel('tmp.xlsx', index_col=None, header=None)  # doctest: +SKIP\n",
      "         0         1      2\n",
      "    0  NaN      Name  Value\n",
      "    1  0.0   string1      1\n",
      "    2  1.0   string2      2\n",
      "    3  2.0  #Comment      3\n",
      "    \n",
      "    Column types are inferred but can be explicitly specified\n",
      "    \n",
      "    >>> pd.read_excel('tmp.xlsx', index_col=0,\n",
      "    ...               dtype={'Name': str, 'Value': float})  # doctest: +SKIP\n",
      "           Name  Value\n",
      "    0   string1    1.0\n",
      "    1   string2    2.0\n",
      "    2  #Comment    3.0\n",
      "    \n",
      "    True, False, and NA values, and thousands separators have defaults,\n",
      "    but can be explicitly specified, too. Supply the values you would like\n",
      "    as strings or lists of strings!\n",
      "    \n",
      "    >>> pd.read_excel('tmp.xlsx', index_col=0,\n",
      "    ...               na_values=['string1', 'string2'])  # doctest: +SKIP\n",
      "           Name  Value\n",
      "    0       NaN      1\n",
      "    1       NaN      2\n",
      "    2  #Comment      3\n",
      "    \n",
      "    Comment lines in the excel input file can be skipped using the `comment` kwarg\n",
      "    \n",
      "    >>> pd.read_excel('tmp.xlsx', index_col=0, comment='#')  # doctest: +SKIP\n",
      "          Name  Value\n",
      "    0  string1    1.0\n",
      "    1  string2    2.0\n",
      "    2     None    NaN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.read_excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav = pd.Series(data.iloc[:, 1])\n",
    "nav.set_axis(data.iloc[:, 0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "日期\n",
       "2016-02-04    1.000000\n",
       "2016-02-05    0.990151\n",
       "2016-02-15    0.983550\n",
       "2016-02-16    1.023214\n",
       "2016-02-17    1.034697\n",
       "2016-02-18    1.037489\n",
       "2016-02-19    1.033865\n",
       "2016-02-22    1.051731\n",
       "2016-02-23    1.047394\n",
       "2016-02-24    1.053989\n",
       "2016-02-25    1.146997\n",
       "2016-02-26    1.158805\n",
       "2016-02-29    1.142738\n",
       "2016-03-01    1.176665\n",
       "2016-03-02    1.257789\n",
       "2016-03-03    1.261391\n",
       "2016-03-04    1.295182\n",
       "2016-03-07    1.328765\n",
       "2016-03-08    1.325715\n",
       "2016-03-09    1.310948\n",
       "2016-03-10    1.285766\n",
       "2016-03-11    1.289865\n",
       "2016-03-14    1.237914\n",
       "2016-03-15    1.245207\n",
       "2016-03-16    1.260291\n",
       "2016-03-17    1.275017\n",
       "2016-03-18    1.284954\n",
       "2016-03-21    1.319502\n",
       "2016-03-22    1.317281\n",
       "2016-03-23    1.323421\n",
       "                ...   \n",
       "2019-02-22    5.887465\n",
       "2019-02-25    5.981135\n",
       "2019-02-26    5.972193\n",
       "2019-02-27    5.949842\n",
       "2019-02-28    5.964151\n",
       "2019-03-01    5.919033\n",
       "2019-03-04    5.937737\n",
       "2019-03-05    6.098174\n",
       "2019-03-06    6.190745\n",
       "2019-03-07    6.230118\n",
       "2019-03-08    6.070938\n",
       "2019-03-11    6.163459\n",
       "2019-03-12    6.283524\n",
       "2019-03-13    6.171520\n",
       "2019-03-14    6.101165\n",
       "2019-03-15    6.133867\n",
       "2019-03-18    6.218146\n",
       "2019-03-19    6.193522\n",
       "2019-03-20    6.206993\n",
       "2019-03-21    6.262391\n",
       "2019-03-22    6.306102\n",
       "2019-03-25    6.355826\n",
       "2019-03-26    6.333167\n",
       "2019-03-27    6.359434\n",
       "2019-03-28    6.312819\n",
       "2019-03-29    6.234556\n",
       "2019-04-01    6.546627\n",
       "2019-04-02    6.521079\n",
       "2019-04-03    6.565389\n",
       "2019-04-04    6.547663\n",
       "Name: CTA净值, Length: 770, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import empyrical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empyrical.cum_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = empyrical.simple_returns(nav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "日期\n",
       "2016-02-05   -0.009849\n",
       "2016-02-15   -0.006667\n",
       "2016-02-16    0.040327\n",
       "2016-02-17    0.011223\n",
       "2016-02-18    0.002699\n",
       "2016-02-19   -0.003493\n",
       "2016-02-22    0.017280\n",
       "2016-02-23   -0.004123\n",
       "2016-02-24    0.006296\n",
       "2016-02-25    0.088244\n",
       "2016-02-26    0.010295\n",
       "2016-02-29   -0.013865\n",
       "2016-03-01    0.029689\n",
       "2016-03-02    0.068944\n",
       "2016-03-03    0.002863\n",
       "2016-03-04    0.026789\n",
       "2016-03-07    0.025929\n",
       "2016-03-08   -0.002295\n",
       "2016-03-09   -0.011139\n",
       "2016-03-10   -0.019209\n",
       "2016-03-11    0.003188\n",
       "2016-03-14   -0.040276\n",
       "2016-03-15    0.005891\n",
       "2016-03-16    0.012114\n",
       "2016-03-17    0.011684\n",
       "2016-03-18    0.007793\n",
       "2016-03-21    0.026887\n",
       "2016-03-22   -0.001683\n",
       "2016-03-23    0.004661\n",
       "2016-03-24   -0.017784\n",
       "                ...   \n",
       "2019-02-22    0.009173\n",
       "2019-02-25    0.015910\n",
       "2019-02-26   -0.001495\n",
       "2019-02-27   -0.003742\n",
       "2019-02-28    0.002405\n",
       "2019-03-01   -0.007565\n",
       "2019-03-04    0.003160\n",
       "2019-03-05    0.027020\n",
       "2019-03-06    0.015180\n",
       "2019-03-07    0.006360\n",
       "2019-03-08   -0.025550\n",
       "2019-03-11    0.015240\n",
       "2019-03-12    0.019480\n",
       "2019-03-13   -0.017825\n",
       "2019-03-14   -0.011400\n",
       "2019-03-15    0.005360\n",
       "2019-03-18    0.013740\n",
       "2019-03-19   -0.003960\n",
       "2019-03-20    0.002175\n",
       "2019-03-21    0.008925\n",
       "2019-03-22    0.006980\n",
       "2019-03-25    0.007885\n",
       "2019-03-26   -0.003565\n",
       "2019-03-27    0.004147\n",
       "2019-03-28   -0.007330\n",
       "2019-03-29   -0.012397\n",
       "2019-04-01    0.050055\n",
       "2019-04-02   -0.003902\n",
       "2019-04-03    0.006795\n",
       "2019-04-04   -0.002700\n",
       "Name: CTA净值, Length: 769, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1736644967217509"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empyrical.annual_return(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empyrical.annual_volatility(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6355712447388737"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empyrical.sharpe_ratio(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.756106152541891"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empyrical.calmar_ratio(ret)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
